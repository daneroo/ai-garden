# /// script
# dependencies = [
#   "mlx-audio>=0.0.1",
#   "soundfile>=0.12.1",
#   "numpy",
#   "mlx",
# ]
# ///

"""
Qwen3-TTS voice cloning generator.
Uses the Base model to clone a voice from a reference audio sample.

Usage:
    uv run --prerelease=allow clone.py --help
    uv run --prerelease=allow clone.py --voice serkis --play
    uv run --prerelease=allow clone.py --voice kenny --play
    uv run --prerelease=allow clone.py --ref-audio my.wav --ref-text "transcript..."
"""
import argparse
import sys
import subprocess
from pathlib import Path
from mlx_audio.tts.utils import load_model

# =============================================================================
# MODEL — Base models support voice cloning via ref_audio + ref_text
# =============================================================================
# Either Base model works for cloning (both accept ref_audio/ref_text):
#   - mlx-community/Qwen3-TTS-12Hz-0.6B-Base-bf16
#   - mlx-community/Qwen3-TTS-12Hz-1.7B-Base-bf16
# Both have empty spk_id (no named voices); that's expected for cloning.
# CustomVoice models are for named voices (see basic.py).
# =============================================================================
MODEL_ID = "mlx-community/Qwen3-TTS-12Hz-1.7B-Base-bf16"

DEFAULT_TEXT_FILE = "these-laurence-edited.txt"

# Preset voice names. Reference audio + transcript are in data/reference/,
# generated by prepare-reference-voices.sh (not checked into git).
PRESET_VOICES = ["serkis", "kenny"]
REF_DIR = Path("data/reference")

def main():
    class Formatter(argparse.ArgumentDefaultsHelpFormatter, argparse.RawDescriptionHelpFormatter):
        pass

    parser = argparse.ArgumentParser(
        description="Qwen3-TTS Voice Cloning Generator (Base model)",
        epilog=f"""\
preset voices: {', '.join(PRESET_VOICES)}

setup (extract reference clips — run once):
  ./prepare-reference-voices.sh

examples:
  uv run --prerelease=allow clone.py --voice serkis --play
  uv run --prerelease=allow clone.py --voice kenny --play
  uv run --prerelease=allow clone.py --ref-audio my.wav --ref-text "transcript..." """,
        formatter_class=Formatter,
    )
    parser.add_argument("--text-file", type=str, default=DEFAULT_TEXT_FILE, help="Path to target text file")
    parser.add_argument("--voice", type=str, default=None, help=f"Preset voice: {', '.join(PRESET_VOICES)}")
    parser.add_argument("--ref-audio", type=str, default=None, help="Path to reference audio file")
    parser.add_argument("--ref-text", type=str, default=None, help="Transcript of reference audio")
    parser.add_argument("--output", type=str, default="data/outputs/output_clone.wav", help="Output WAV file")
    parser.add_argument("--play", action="store_true", help="Play audio after generation")

    args = parser.parse_args()

    # Resolve voice preset vs manual ref-audio/ref-text
    if args.voice:
        name = args.voice.lower()
        if name not in PRESET_VOICES:
            print(f"Error: Unknown voice '{args.voice}'. Available: {', '.join(PRESET_VOICES)}")
            sys.exit(1)
        ref_audio_path = REF_DIR / f"reference_voice_{name}.wav"
        ref_text_path = REF_DIR / f"reference_voice_{name}.txt"
        if not ref_audio_path.exists() or not ref_text_path.exists():
            print(f"Missing reference files for '{name}'. Run: ./prepare-reference-voices.sh")
            sys.exit(1)
        ref_text = ref_text_path.read_text().strip()
        # Default output includes voice name
        if args.output == "data/outputs/output_clone.wav":
            p = Path(args.output)
            args.output = str(p.parent / f"{p.stem}_{name}{p.suffix}")
        print(f"Using preset voice: {name}")
    elif args.ref_audio and args.ref_text:
        ref_audio_path = Path(args.ref_audio)
        ref_text = args.ref_text
    else:
        print("Error: Provide --voice <preset> or both --ref-audio and --ref-text.")
        sys.exit(1)

    # Read target text
    text_path = Path(args.text_file)
    if not text_path.exists():
        print(f"Error: Text file '{text_path}' not found.")
        sys.exit(1)

    text = text_path.read_text().strip()
    if not text:
        print(f"Error: Text file '{text_path}' is empty.")
        sys.exit(1)

    # Verify reference audio
    if not ref_audio_path.exists():
        print(f"Error: Reference audio '{ref_audio_path}' not found.")
        print("See README.md for extraction instructions.")
        sys.exit(1)

    print(f"Loading model: {MODEL_ID}")
    print("Warning: Expect warning about tokenizer (possibly because of pre-release)\n")
    model = load_model(MODEL_ID)

    # Load reference audio
    import soundfile as sf
    import numpy as np
    import mlx.core as mx

    ref_audio_data, _ = sf.read(str(ref_audio_path))
    if ref_audio_data.ndim > 1:
        ref_audio_data = ref_audio_data.mean(axis=1)
    ref_audio_mx = mx.array(ref_audio_data)

    print(f"Generating cloned audio...")
    print(f"Reference: {ref_audio_path}")
    print(f"Ref text: {ref_text[:80]}...")
    print(f"Target text: {text[:80]}...")

    results = list(model.generate(
        text=text,
        ref_audio=ref_audio_mx,
        ref_text=ref_text,
        language="English",
    ))

    if not results:
        print("Error: No audio generated.")
        return

    audio_array = results[0].audio

    Path(args.output).parent.mkdir(parents=True, exist_ok=True)
    sf.write(args.output, np.array(audio_array), model.sample_rate)
    
    print(f"Output: {args.output}")
    print(f"ffplay -autoexit -nodisp -hide_banner -loglevel error {args.output}")
    if args.play:
        subprocess.run(["ffplay", "-autoexit", "-nodisp", "-hide_banner", "-loglevel", "error", args.output])

if __name__ == "__main__":
    main()
