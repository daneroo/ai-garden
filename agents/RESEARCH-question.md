# Agentic Harnesses

## Deep research question

I consolidating and researching my agentic development workflow. I currently
use:

- engine: Antigravity, opencode, claude-code, codex
- subscriptions: Claude Pro, ChatGPTPlus, Google AI Pro, OPenCode Zen,
  openclaw(clawdbot)
- top models: across different subs: opus-4.5 (Claude Pro,Antigravity), Kimi
  K2.5, openai/gpt-5.2-[codex], and their lesser brethren
- agentic harnesses I have tried:
  - [agentic-cli](https://github.com/Cluster444/agentic) over opencode
  - [oh-my-opencode/sysiphus](https://github.com/code-yeongyu/oh-my-opencode)
    over opencode

Help me make sense of all of this! This space is moving extremely fast, and so
up to date information is critical I would like to achieve some level of
**provable**, state of the art workflow. I think this requires that we construct
some form of eval, where we can benchmark different workflows to compare them. I
am prepared to develop exemplar development tasks.

- Use case: primarily coding/development agents (e.g., autonomous code
  generation, refactoring, debugging) use cases; - full stack development in
  monorepos - frontend,backend,infrastrucure as code, Typescript
  (bun,tanstack-start), go, (infrastructure as code as a stretch).
- Evaluation scope: subjective evaluation, cost efficiency, completion metric of
  some kind
- Infrastructure constraints: I have MacOS, or Proxmox, or any Linux is an
  option (All Homelab local)
- Exemplar Tasks: I have a few webapps/cli's in mind already

The research should address:

- agentic loops, that can operate over longer periods of time autonomously (not
  just single turn instructions) a.k.k Human in the Loop)
- parallel agents (and how to organize them (multiple git-trees, forks,
  vm's/containers)
- specific harness/loops/agents
- ways to leverage, reusable skill/agents - through mechanisms like Claude
  Marketplace (like: /plugin install plugin-name@claude-plugins-official)

Be thorough, and provide guidance on how to do further research or experiments.

We need this research to be accurate and authoritative, so we can build a great
implementation plan to roll this out progressively. and perform real experiments
to evaluate and evolve our approach
